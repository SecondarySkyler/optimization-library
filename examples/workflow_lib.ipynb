{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518738b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianmurtas/miniconda3/envs/thesis/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yprov4ml\n",
    "import codecarbon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15f6c7",
   "metadata": {},
   "source": [
    "# Definition of machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496eb111",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNet\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_size, dropout):\n\u001b[32m      3\u001b[39m         \u001b[38;5;28msuper\u001b[39m(Net, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, model_size, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        def get_layer_sizes(model_size): \n",
    "            if model_size == \"small\": \n",
    "                return 64, 32\n",
    "            elif model_size == \"medium\": \n",
    "                return 512, 256\n",
    "            else: \n",
    "                return 1024, 256\n",
    "\n",
    "        l1, l2 = get_layer_sizes(model_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(12544, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, epochs, batch_size, dropout, model_size):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model = Net(model_size, dropout=dropout).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    scheduler = None\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for _ in range(epochs): \n",
    "        for data in tqdm(trainloader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def validate(model, batch_size=128):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total} %')\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb296d86",
   "metadata": {},
   "source": [
    "We define the objective function that will be optimized by the hyperparameter optimization library.\n",
    "Here we also want to track the carbon emissions during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    lr = params[\"lr\"]\n",
    "    epochs = params[\"epochs\"]\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    dropout = 0.25\n",
    "    model_size = \"small\"\n",
    "\n",
    "    tracker = codecarbon.EmissionsTracker(\n",
    "        save_to_api=False,\n",
    "        save_to_file=False,\n",
    "        save_to_logger=False,\n",
    "        log_level=\"error\",\n",
    "    )\n",
    "    tracker.start_task()\n",
    "    model = train(lr, epochs, batch_size, dropout, model_size)\n",
    "    emissions = tracker.stop_task()\n",
    "    \n",
    "    accuracy = validate(model, batch_size)\n",
    "\n",
    "    return accuracy, emissions.energy_consumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedd72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianmurtas/miniconda3/envs/thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from library import Experiment, SearchSpace, FloatParameter, IntParameter, OptimizationParameters, OptimizerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c28e2e",
   "metadata": {},
   "source": [
    "We first define which parameters we want to optimize and their bounds. This will be used to create the search space for the optimization.\n",
    "The output list will contain the metrics we want to optimize, in this case accuracy and energy consumed.\n",
    "The directions list will contain the direction of optimization for each output metric, in this case we want to maximize accuracy and minimize energy consumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20dd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = FloatParameter(\"lr\", 0.0001, 0.001)\n",
    "batch_size = IntParameter(\"batch_size\", 16, 32)\n",
    "epochs = IntParameter(\"epochs\", 5, 10)\n",
    "search_space = SearchSpace(parameters=[lr, batch_size, epochs])\n",
    "\n",
    "opt_params = OptimizationParameters(\n",
    "    input=search_space,\n",
    "    output=[\"accuracy\", \"energy_consumed\"],\n",
    "    directions=[\"maximize\", \"minimize\"]\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(\n",
    "    200, 10, \"ucb\", 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11422b30",
   "metadata": {},
   "source": [
    "Then we set up the Experiment (which represents an optimization task) and run the optimize function with a given objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c67d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(\n",
    "    optimization_parameters=opt_params,\n",
    "    optimizer_config=optimizer_config,\n",
    "    path_to_prov=\"./prov\",\n",
    "    n_iter=2\n",
    ")\n",
    "\n",
    "exp.optimize(objective_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
